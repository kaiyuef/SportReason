# ------------------------------------------------Global Paths------------------------------------------------#
model2path:
  e5: "intfloat/e5-base-v2"
  bge: "BAAI/bge-base-en-v1.5"
  contriever: "facebook/contriever"
  # --- LLAMA family (unchanged) ---
  llama2-7B-chat: "meta-llama/Llama-2-7b-chat-hf"
  llama2-7B: "meta-llama/Llama-2-7b-hf"
  llama2-13B: "meta-llama/Llama-2-13b-hf"
  llama2-13B-chat: "meta-llama/Llama-2-13b-chat-hf"
  # --- NEW: checkpoint used by R1‑Searcher ------------------------------ # <<< new
  qwen25_r1searcher: "XXsongLALA/Qwen-2.5-7B-base-RAG-RL"                 # <<< new

model2pooling:
  e5: "mean"
  bge: "cls"
  contriever: "mean"
  jina: "mean"
  dpr: "pooler"

method2index:
  bge: "FlashRAG/indexes/wiki_faiss_bge_final/bge_Flat.index"   # <<< set if you already built the BGE index
  bm25: ~
  e5: ~
  contriever: ~
  clip:
    text: "path/to/text_index"
    image: "path/to/image_index"

# ------------------------------------------------Environment Settings------------------------------------------------#
data_dir: "FlashRAG/dataset/"
save_dir: "FlashRAG/outputs/numsports_exp/"
save_note: "r1-searcher"                        # <<< so outputs land in outputs/r1-searcher
gpu_id: "0"                                     # <<< adjust to your node
dataset_name: "numsports"                       # <<< default; change freely
split: ["test"]
test_sample_num: ~
random_sample: False
seed: 2024
save_intermediate_data: True

# -------------------------------------------------Retrieval Settings------------------------------------------------#
retrieval_method: "bge"                         # R1 uses the same retriever you pick here
index_path: "FlashRAG/indexes/wiki_faiss_bge_final/bge_Flat.index"
retrieval_topk: 5
retrieval_batch_size: 256
retrieval_use_fp16: True
retrieval_query_max_length: 128
silent_retrieval: True

# -------------------------------------------------Generator / Reasoner Settings------------------------------------------------#
framework: "vllm"                               # <<< R1 is heavy; vLLM cheaper than HF
generator_model: "qwen25_r1searcher"            # <<< lookup key in model2path
generator_model_path: "XXsongLALA/Qwen-2.5-7B-base-RAG-RL"   # explicit for clarity
generator_max_input_len: 16384                  # <<< R1 needs long context
generator_batch_size: 4
generation_params:                              # <<< greedy decoding = how R1 was trained
  max_tokens: 512
  temperature: 0.0
  top_p: 1.0
  skip_special_tokens: false
gpu_memory_utilization: 0.85
use_fid: False

# ------------ Reasoning‑specific knobs (parsed by ReasoningPipeline) ------------ #
r1_max_steps: 8                 # max self‑ask turns before stopping (default=∞)
search_topk: 5                  # doc candidates fetched each turn; keep ≤ retrieval_topk
stop_keywords: ["So the answer is:"]   # early‑stop string used in the original prompt

# -------------------------------------------------Evaluation Settings------------------------------------------------#
metrics: ["em", "f1", "input_tokens", "precision", "recall"]
metric_setting:
  retrieval_recall_topk: 5
  tokenizer_name: "gpt-4o"
save_metric_score: True
